{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "## Udacity Self Driving Car Engineer Nanodegree\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Step 1: Chessboard images\n",
    "First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4))\n",
    "        ax1.imshow(cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=18)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('With Corners', fontsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Undistort Images\n",
    "To get undistorted images, cv2.undistort is used, which will get arguments from cv2.calibrateCamera like the distortion coefficient, the camera matrix to return a undistorted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the undistort function for convenience.\n",
    "def undistort(image, show=True, read = True):\n",
    "    if read:\n",
    "        img = cv2.imread(image)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx) # destination image/ undistorted image\n",
    "    if show:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9,6))\n",
    "        ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=18)\n",
    "        ax2.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted Image', fontsize=18)\n",
    "    else:\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort the test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    undistort(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: perspective transform to \"birds-eye view\"\n",
    "In this section the undistorted images will be transformed to \"bird-eye view\" images so that the lane lines could be parallel to each other. Then the polynomials could be fitted into the lane lines so that the curvature could be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define birds_eye() function for convenience\n",
    "def birds_eye(img, display=True, read = True):\n",
    "    if read:\n",
    "        undist = undistort(img, show = False)\n",
    "    else:\n",
    "        undist = undistort(img, show = False, read=False) \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    offset = 0\n",
    "    src = np.float32([[515, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    if display:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 6))\n",
    "        #f.tight_layout()\n",
    "        ax1.imshow(cv2.cvtColor(undist, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Undistorted Image', fontsize=20)\n",
    "        ax2.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted and Warped Image', fontsize=20)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    else:\n",
    "        return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    birds_eye(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Binary Thresholds\n",
    "\n",
    "In this section, by using binary thresholds, warped images are transformed to different color spaces. In the transfermed images, the lane lines including the solid yellow line and the dashed white line. \n",
    "I choose three color spaces, which are HLS color space, LUV color space, LAB color space, and then choose differrent channels to check their functionalities. After several trials, I finnally pick up three channels from these three color space, which are S channel from HLS color space, L channel LUV color space and B channel from LAB color space. The functionalities of these three channels are shown as below:\n",
    "- The S Channel of the HLS color space, with a threshold from 190 to 255, works well on detecting both lane lines but is apt to interfered by shadows. \n",
    "- The B channel of LAB color space with a threshold from 160 to 255 could successfully detect the yellow line but would missed the white line.  \n",
    "- The L Channel of the LUV color space, with a threshold  from 240 to 255, is capable of picking up the white line, but missed the yellow line to eliminate the noises caused by the color differences of the pavement.\n",
    "Finally, I created a combined binary threshold which combined the pixels detected by these three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fristly try to convert the image to HLS, LUV, Lab images and selsect the appropriate channels.\n",
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    # After several tries, I select S channel in HLS, L channel in LUV, B channel in LAB.\n",
    "    img, M = birds_eye(image, display = False)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]\n",
    "\n",
    "\n",
    "    \n",
    "    # Plotting thresholded images\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey='col', sharex='row', figsize=(10,4))\n",
    "    f.tight_layout()\n",
    "        \n",
    "    ax1.set_title('schannel_hls', fontsize=16)\n",
    "    ax1.imshow(hls)\n",
    "        \n",
    "    ax2.set_title('lchannel_luv', fontsize=16)\n",
    "    ax2.imshow(luv)\n",
    "        \n",
    "    ax3.set_title('bchannel_lab', fontsize=16)\n",
    "    ax3.imshow(lab)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary thresholded images to isolate lane line pixels\n",
    "def apply_thresholds(image, show=True):\n",
    "    img, M = birds_eye(image, display = False)\n",
    "\n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    \n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "\n",
    "    b_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]   \n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 230\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "    \n",
    "    b_thresh_min = 155\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    l_thresh_min = 225\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "       \n",
    "    combined_binary = np.zeros_like(s_channel)\n",
    "    combined_binary[(b_binary == 1) | (s_binary == 1) | (l_binary == 1)] = 1\n",
    "\n",
    "    if show == True:\n",
    "        # Plotting thresholded images\n",
    "        f, ((ax1, ax2, ax3), (ax4,ax5, ax6)) = plt.subplots(2, 3, sharey='col', sharex='row', figsize=(10,4))\n",
    "        f.tight_layout()\n",
    "        \n",
    "        ax1.set_title('Original Image', fontsize=16)\n",
    "        ax1.imshow(cv2.cvtColor(undistort(image, show=False),cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        ax2.set_title('Warped Image', fontsize=16)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype('uint8'))\n",
    "        \n",
    "        ax3.set_title('s binary threshold', fontsize=16)\n",
    "        ax3.imshow(s_binary, cmap='gray')\n",
    "        \n",
    "        ax4.set_title('b binary threshold', fontsize=16)\n",
    "        ax4.imshow(b_binary, cmap='gray')\n",
    "        \n",
    "        ax5.set_title('l binary threshold', fontsize=16)\n",
    "        ax5.imshow(l_binary, cmap='gray')\n",
    "\n",
    "        ax6.set_title('Combined color thresholds', fontsize=16)\n",
    "        ax6.imshow(combined_binary, cmap='gray')\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    apply_thresholds(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Polynominal Fitting & Curvature Calculation\n",
    "In this part, the combined binary images are used to pick upo the pixels to fit a polynomial to each lane line. And the lane will be marked with green color. Moreover, the radius of the curvature will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_lane(image):\n",
    "    \n",
    "    combined_binary = apply_thresholds(image, show=False)\n",
    "    \n",
    "    rightx = []\n",
    "    righty = []\n",
    "    leftx = []\n",
    "    lefty = []\n",
    "    \n",
    "    x, y = np.nonzero(np.transpose(combined_binary))\n",
    "    i = 720\n",
    "    j = 620\n",
    "    while j >= 0:\n",
    "        histogram = np.sum(combined_binary[j:i,:], axis=0)\n",
    "        left_peak = np.argmax(histogram[:640])\n",
    "        x_idx = np.where((((left_peak - 25) < x)&(x < (left_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            leftx.extend(x_window.tolist())\n",
    "            lefty.extend(y_window.tolist())\n",
    "\n",
    "        right_peak = np.argmax(histogram[640:]) + 640\n",
    "        x_idx = np.where((((right_peak - 25) < x)&(x < (right_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            rightx.extend(x_window.tolist())\n",
    "            righty.extend(y_window.tolist())\n",
    "        i -= 90\n",
    "        j -= 90\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    rightx_int = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    rightx = np.append(rightx,rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx,right_fit[0]*0**2 + right_fit[1]*0 + right_fit[2])\n",
    "    righty = np.append(righty, 0)\n",
    "    leftx_int = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx,left_fit[0]*0**2 + left_fit[1]*0 + left_fit[2])\n",
    "    lefty = np.append(lefty, 0)\n",
    "    lsort = np.argsort(lefty)\n",
    "    rsort = np.argsort(righty)\n",
    "    lefty = lefty[lsort]\n",
    "    leftx = leftx[lsort]\n",
    "    righty = righty[rsort]\n",
    "    rightx = rightx[rsort]\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    \n",
    "    # Measure Radius of Curvature for each lane line\n",
    "    ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*np.max(lefty) + left_fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*np.max(lefty) + right_fit_cr[1])**2)**1.5) \\\n",
    "                                    /np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    # Calculate the position of the vehicle\n",
    "    center = abs(640 - ((rightx_int+leftx_int)/2))\n",
    "    \n",
    "    offset = 0 \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    src = np.float32([[515, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([left_fitx, lefty])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, righty]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (combined_binary.shape[1], combined_binary.shape[0]))\n",
    "    result = cv2.addWeighted(mpimg.imread(image), 1, newwarp, 0.5, 0)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(9, 6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(cv2.cvtColor((birds_eye(image, display=False)[0]), cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_xlim(0, 1280)\n",
    "    ax1.set_ylim(0, 720)\n",
    "    ax1.plot(left_fitx, lefty, color='green', linewidth=3)\n",
    "    ax1.plot(right_fitx, righty, color='green', linewidth=3)\n",
    "    ax1.set_title('Fit Polynomial to Lane Lines', fontsize=16)\n",
    "    ax1.invert_yaxis() # to visualize as we do the images\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Fill Lane Between Polynomials', fontsize=16)\n",
    "    if center < 640:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m left of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    else:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m right of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    ax2.text(200, 175, 'Radius of curvature is {}m'.format(int((left_curverad + right_curverad)/2)),\n",
    "             style='italic', color='white', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    mark_lane(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:  Video Process Pipeline\n",
    "Build the frame to pick up the pixels of lane lines  and process the video step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to store attributes of each frame\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.x_int = deque(maxlen=10)\n",
    "        self.top = deque(maxlen=10)\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_int = None\n",
    "        self.last_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = deque(maxlen=10)\n",
    "        self.fit1 = deque(maxlen=10)\n",
    "        self.fit2 = deque(maxlen=10)\n",
    "        self.fitx = None\n",
    "        self.pts = []\n",
    "        \n",
    "        # Count the number of frames\n",
    "        self.count = 0\n",
    "        \n",
    "    def found_search(self, x, y):\n",
    "        '''\n",
    "        This function is applied when the lane lines have been detected in the previous frame.\n",
    "        It uses a sliding window to search for lane pixels in close proximity (+/- 25 pixels in the x direction)\n",
    "        around the previous detected polynomial. \n",
    "        '''\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == True: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                yval = np.mean([i,j])\n",
    "                xval = (np.mean(self.fit0))*yval**2 + (np.mean(self.fit1))*yval + (np.mean(self.fit2))\n",
    "                x_idx = np.where((((xval - 25) < x)&(x < (xval + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    np.append(xvals, x_window)\n",
    "                    np.append(yvals, y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) == 0: \n",
    "            self.found = False # If no lane pixels were detected then perform blind search\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    def blind_search(self, x, y, image):\n",
    "        '''\n",
    "        This function is applied in the first few frames and/or if the lane was not successfully detected\n",
    "        in the previous frame. It uses a slinding window approach to detect peaks in a histogram of the\n",
    "        binary thresholded image. Pixels in close proimity to the detected peaks are considered to belong\n",
    "        to the lane lines.\n",
    "        '''\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == False: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                histogram = np.sum(image[j:i,:], axis=0)\n",
    "                if self == Right:\n",
    "                    peak = np.argmax(histogram[640:]) + 640\n",
    "                else:\n",
    "                    peak = np.argmax(histogram[:640])\n",
    "                x_idx = np.where((((peak - 25) < x)&(x < (peak + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    xvals.extend(x_window)\n",
    "                    yvals.extend(y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) > 0:\n",
    "            self.found = True\n",
    "        else:\n",
    "            yvals = self.Y\n",
    "            xvals = self.X\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    def radius_of_curvature(self, xvals, yvals):\n",
    "        ym_per_pix = 5./720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "        fit_cr = np.polyfit(yvals*ym_per_pix, xvals*xm_per_pix, 2)\n",
    "        curverad = ((1 + (2*fit_cr[0]*np.max(yvals) + fit_cr[1])**2)**1.5) \\\n",
    "                                     /np.absolute(2*fit_cr[0])\n",
    "        return curverad\n",
    "    \n",
    "    def sort_vals(self, xvals, yvals):\n",
    "        sorted_index = np.argsort(yvals)\n",
    "        sorted_yvals = yvals[sorted_index]\n",
    "        sorted_xvals = xvals[sorted_index]\n",
    "        return sorted_xvals, sorted_yvals\n",
    "    \n",
    "    def get_intercepts(self, polynomial):\n",
    "        bottom = polynomial[0]*720**2 + polynomial[1]*720 + polynomial[2]\n",
    "        top = polynomial[0]*0**2 + polynomial[1]*0 + polynomial[2]\n",
    "        return bottom, top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Processing Pipeline\n",
    "def process_vid(image):\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    \n",
    "    # Calibrate camera and undistort image\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Perform perspective transform\n",
    "    offset = 0\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[0, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    # Generate binary thresholded images\n",
    "    b_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2Lab)[:,:,2]\n",
    "    l_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2LUV)[:,:,0]  \n",
    "    \n",
    "    # Set the upper and lower thresholds for the b channel\n",
    "    b_thresh_min = 145\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    # Set the upper and lower thresholds for the l channel\n",
    "    l_thresh_min = 215\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "    combined_binary = np.zeros_like(b_binary)\n",
    "    combined_binary[(l_binary == 1) | (b_binary == 1)] = 1\n",
    "    \n",
    "    # Identify all non zero pixels in the image\n",
    "    x, y = np.nonzero(np.transpose(combined_binary)) \n",
    "\n",
    "    if Left.found == True: # Search for left lane pixels around previous polynomial\n",
    "        leftx, lefty, Left.found = Left.found_search(x, y)\n",
    "        \n",
    "    if Right.found == True: # Search for right lane pixels around previous polynomial\n",
    "        rightx, righty, Right.found = Right.found_search(x, y)\n",
    "\n",
    "            \n",
    "    if Right.found == False: # Perform blind search for right lane lines\n",
    "        rightx, righty, Right.found = Right.blind_search(x, y, combined_binary)\n",
    "            \n",
    "    if Left.found == False:# Perform blind search for left lane lines\n",
    "        leftx, lefty, Left.found = Left.blind_search(x, y, combined_binary)\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "            \n",
    "    # Calculate left polynomial fit based on detected pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    leftx_int, left_top = Left.get_intercepts(left_fit)\n",
    "    \n",
    "    # Average intercepts across n frames\n",
    "    Left.x_int.append(leftx_int)\n",
    "    Left.top.append(left_top)\n",
    "    leftx_int = np.mean(Left.x_int)\n",
    "    left_top = np.mean(Left.top)\n",
    "    Left.lastx_int = leftx_int\n",
    "    Left.last_top = left_top\n",
    "    \n",
    "    # Add averaged intercepts to current x and y vals\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx, left_top)\n",
    "    lefty = np.append(lefty, 0)\n",
    "    \n",
    "    # Sort detected pixels based on the yvals\n",
    "    leftx, lefty = Left.sort_vals(leftx, lefty)\n",
    "    \n",
    "    Left.X = leftx\n",
    "    Left.Y = lefty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), \n",
    "                np.mean(Left.fit1), \n",
    "                np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    Left.fitx = left_fitx\n",
    "    \n",
    "    # Calculate right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    rightx_int, right_top = Right.get_intercepts(right_fit)\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Right.x_int.append(rightx_int)\n",
    "    rightx_int = np.mean(Right.x_int)\n",
    "    Right.top.append(right_top)\n",
    "    right_top = np.mean(Right.top)\n",
    "    Right.lastx_int = rightx_int\n",
    "    Right.last_top = right_top\n",
    "    rightx = np.append(rightx, rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx, right_top)\n",
    "    righty = np.append(righty, 0)\n",
    "    \n",
    "    # Sort right lane pixels\n",
    "    rightx, righty = Right.sort_vals(rightx, righty)\n",
    "    Right.X = rightx\n",
    "    Right.Y = righty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "        \n",
    "    # Compute radius of curvature for each lane in meters\n",
    "    left_curverad = Left.radius_of_curvature(leftx, lefty)\n",
    "    right_curverad = Right.radius_of_curvature(rightx, righty)\n",
    "        \n",
    "    # Only print the radius of curvature every 3 frames for improved readability\n",
    "    if Left.count % 3 == 0:\n",
    "        Left.radius = left_curverad\n",
    "        Right.radius = right_curverad\n",
    "        \n",
    "    # Calculate the vehicle position relative to the center of the lane\n",
    "    position = (rightx_int+leftx_int)/2\n",
    "    distance_from_center = abs((640 - position)*3.7/700) \n",
    "                \n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([Left.fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_(pts), (34,255,34))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.5, 0)\n",
    "        \n",
    "    # Print distance from center on video\n",
    "    if position > 640:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    else:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature {}(m)'.format(int((Left.radius+Right.radius)/2)), (120,140),\n",
    "             fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    Left.count += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Video Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video result.mp4.\n",
      "Moviepy - Writing video result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready result.mp4\n"
     ]
    }
   ],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"360\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('result.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/485 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video challenge_result.mp4.\n",
      "Moviepy - Writing video challenge_result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready challenge_result.mp4\n"
     ]
    }
   ],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "challenge_output = 'challenge_result.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "challenge_clip = clip1.fl_image(process_vid) \n",
    "challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"360\" controls>\n",
       "  <source src=\"challenge_result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('challenge_result.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1199 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video harder_challenge_result.mp4.\n",
      "Moviepy - Writing video harder_challenge_result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready harder_challenge_result.mp4\n"
     ]
    }
   ],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "challenge_output = 'harder_challenge_result.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "challenge_clip = clip1.fl_image(process_vid) \n",
    "challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"360\" controls>\n",
       "  <source src=\"harder_challenge_result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('harder_challenge_result.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
