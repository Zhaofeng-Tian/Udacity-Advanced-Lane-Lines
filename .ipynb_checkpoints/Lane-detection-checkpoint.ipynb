{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "## Udacity Self Driving Car Engineer Nanodegree\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Step 1: Chessboard images\n",
    "First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4))\n",
    "        ax1.imshow(cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=18)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('With Corners', fontsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Undistort Images\n",
    "To get undistorted images, cv2.undistort is used, which will get arguments from cv2.calibrateCamera like the distortion coefficient, the camera matrix to return a undistorted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the undistort function for convenience.\n",
    "def undistort(image, show=True, read = True):\n",
    "    if read:\n",
    "        img = cv2.imread(image)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx) # destination image/ undistorted image\n",
    "    if show:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9,6))\n",
    "        ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=18)\n",
    "        ax2.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted Image', fontsize=18)\n",
    "    else:\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort the test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    undistort(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: perspective transform to \"birds-eye view\"\n",
    "In this section the undistorted images will be transformed to \"bird-eye view\" images so that the lane lines could be parallel to each other. Then the polynomials could be fitted into the lane lines so that the curvature could be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define birds_eye() function for convenience\n",
    "def birds_eye(img, display=True, read = True):\n",
    "    if read:\n",
    "        undist = undistort(img, show = False)\n",
    "    else:\n",
    "        undist = undistort(img, show = False, read=False) \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    offset = 0\n",
    "    src = np.float32([[515, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    if display:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 6))\n",
    "        #f.tight_layout()\n",
    "        ax1.imshow(cv2.cvtColor(undist, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Undistorted Image', fontsize=20)\n",
    "        ax2.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Undistorted and Warped Image', fontsize=20)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    else:\n",
    "        return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    birds_eye(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Binary Thresholds\n",
    "\n",
    "In this section, by using binary thresholds, warped images are transformed to different color spaces. In the transfermed images, the lane lines including the solid yellow line and the dashed white line. \n",
    "I choose three color spaces, which are HLS color space, LUV color space, LAB color space, and then choose differrent channels to check their functionalities. After several trials, I finnally pick up three channels from these three color space, which are S channel from HLS color space, L channel LUV color space and B channel from LAB color space. The functionalities of these three channels are shown as below:\n",
    "- The S Channel of the HLS color space, with a threshold from 190 to 255, works well on detecting both lane lines but is apt to interfered by shadows. \n",
    "- The B channel of LAB color space with a threshold from 160 to 255 could successfully detect the yellow line but would missed the white line.  \n",
    "- The L Channel of the LUV color space, with a threshold  from 240 to 255, is capable of picking up the white line, but missed the yellow line to eliminate the noises caused by the color differences of the pavement.\n",
    "Finally, I created a combined binary threshold which combined the pixels detected by these three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fristly try to convert the image to HLS, LUV, Lab images and selsect the appropriate channels.\n",
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    # After several tries, I select S channel in HLS, L channel in LUV, B channel in LAB.\n",
    "    img, M = birds_eye(image, display = False)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]\n",
    "\n",
    "\n",
    "    \n",
    "    # Plotting thresholded images\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey='col', sharex='row', figsize=(10,4))\n",
    "    f.tight_layout()\n",
    "        \n",
    "    ax1.set_title('schannel_hls', fontsize=16)\n",
    "    ax1.imshow(hls)\n",
    "        \n",
    "    ax2.set_title('lchannel_luv', fontsize=16)\n",
    "    ax2.imshow(luv)\n",
    "        \n",
    "    ax3.set_title('bchannel_lab', fontsize=16)\n",
    "    ax3.imshow(lab)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary thresholded images to isolate lane line pixels\n",
    "def apply_thresholds(image, show=True):\n",
    "    img, M = birds_eye(image, display = False)\n",
    "\n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    \n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "\n",
    "    b_channel = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]   \n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 230\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "    \n",
    "    b_thresh_min = 155\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    l_thresh_min = 225\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "       \n",
    "    combined_binary = np.zeros_like(s_channel)\n",
    "    combined_binary[(b_binary == 1) | (s_binary == 1) | (l_binary == 1)] = 1\n",
    "\n",
    "    if show == True:\n",
    "        # Plotting thresholded images\n",
    "        f, ((ax1, ax2, ax3), (ax4,ax5, ax6)) = plt.subplots(2, 3, sharey='col', sharex='row', figsize=(10,4))\n",
    "        f.tight_layout()\n",
    "        \n",
    "        ax1.set_title('Original Image', fontsize=16)\n",
    "        ax1.imshow(cv2.cvtColor(undistort(image, show=False),cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        ax2.set_title('Warped Image', fontsize=16)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype('uint8'))\n",
    "        \n",
    "        ax3.set_title('s binary threshold', fontsize=16)\n",
    "        ax3.imshow(s_binary, cmap='gray')\n",
    "        \n",
    "        ax4.set_title('b binary threshold', fontsize=16)\n",
    "        ax4.imshow(b_binary, cmap='gray')\n",
    "        \n",
    "        ax5.set_title('l binary threshold', fontsize=16)\n",
    "        ax5.imshow(l_binary, cmap='gray')\n",
    "\n",
    "        ax6.set_title('Combined color thresholds', fontsize=16)\n",
    "        ax6.imshow(combined_binary, cmap='gray')\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    apply_thresholds(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lane(image):\n",
    "    \n",
    "    combined_binary = apply_thresholds(image, show=False)\n",
    "    \n",
    "    rightx = []\n",
    "    righty = []\n",
    "    leftx = []\n",
    "    lefty = []\n",
    "    \n",
    "    x, y = np.nonzero(np.transpose(combined_binary))\n",
    "    i = 720\n",
    "    j = 620\n",
    "    while j >= 0:\n",
    "        histogram = np.sum(combined_binary[j:i,:], axis=0)\n",
    "        left_peak = np.argmax(histogram[:640])\n",
    "        x_idx = np.where((((left_peak - 25) < x)&(x < (left_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            leftx.extend(x_window.tolist())\n",
    "            lefty.extend(y_window.tolist())\n",
    "\n",
    "        right_peak = np.argmax(histogram[640:]) + 640\n",
    "        x_idx = np.where((((right_peak - 25) < x)&(x < (right_peak + 25))&((y > j) & (y < i))))\n",
    "        x_window, y_window = x[x_idx], y[x_idx]\n",
    "        if np.sum(x_window) != 0:\n",
    "            rightx.extend(x_window.tolist())\n",
    "            righty.extend(y_window.tolist())\n",
    "        i -= 90\n",
    "        j -= 90\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    rightx_int = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    rightx = np.append(rightx,rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx,right_fit[0]*0**2 + right_fit[1]*0 + right_fit[2])\n",
    "    righty = np.append(righty, 0)\n",
    "    leftx_int = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx,left_fit[0]*0**2 + left_fit[1]*0 + left_fit[2])\n",
    "    lefty = np.append(lefty, 0)\n",
    "    lsort = np.argsort(lefty)\n",
    "    rsort = np.argsort(righty)\n",
    "    lefty = lefty[lsort]\n",
    "    leftx = leftx[lsort]\n",
    "    righty = righty[rsort]\n",
    "    rightx = rightx[rsort]\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    \n",
    "    # Measure Radius of Curvature for each lane line\n",
    "    ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*np.max(lefty) + left_fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*np.max(lefty) + right_fit_cr[1])**2)**1.5) \\\n",
    "                                    /np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    # Calculate the position of the vehicle\n",
    "    center = abs(640 - ((rightx_int+leftx_int)/2))\n",
    "    \n",
    "    offset = 0 \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    src = np.float32([[515, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([left_fitx, lefty])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, righty]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (combined_binary.shape[1], combined_binary.shape[0]))\n",
    "    result = cv2.addWeighted(mpimg.imread(image), 1, newwarp, 0.5, 0)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(9, 6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(cv2.cvtColor((birds_eye(image, display=False)[0]), cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_xlim(0, 1280)\n",
    "    ax1.set_ylim(0, 720)\n",
    "    ax1.plot(left_fitx, lefty, color='green', linewidth=3)\n",
    "    ax1.plot(right_fitx, righty, color='green', linewidth=3)\n",
    "    ax1.set_title('Fit Polynomial to Lane Lines', fontsize=16)\n",
    "    ax1.invert_yaxis() # to visualize as we do the images\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Fill Lane Between Polynomials', fontsize=16)\n",
    "    if center < 640:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m left of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    else:\n",
    "        ax2.text(200, 100, 'Vehicle is {:.2f}m right of center'.format(center*3.7/700),\n",
    "                 style='italic', color='white', fontsize=10)\n",
    "    ax2.text(200, 175, 'Radius of curvature is {}m'.format(int((left_curverad + right_curverad)/2)),\n",
    "             style='italic', color='white', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    fill_lane(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
